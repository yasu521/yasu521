import requests
from collections import defaultdict, Counter
import json
import os
import re
import matplotlib.pyplot as plt
from datetime import datetime, timezone

# ãƒ¢ãƒé¢¨ã®æŸ”ã‚‰ã‹ã„ãƒ‘ã‚¹ãƒ†ãƒ«èª¿ã®ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
monet_colors = [
    "#a8c5dd", "#f5d5b5", "#d4a5a5", "#a3c1ad", "#b2d3c2",
    "#f3e1dd", "#c4b6a4", "#e7d3c8", "#ccd4bf", "#e4d8b4"
]

# ãƒªãƒã‚¸ãƒˆãƒªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
def fetch_repositories():
    url = 'https://api.github.com/user/repos'
    headers = {
        'Authorization': f'token {os.getenv("GITHUB_TOKEN")}'
    }
    params = {
        'per_page': 100,
        'type': 'all'
    }
    repos = []
    while url:
        response = requests.get(url, headers=headers, params=params)
        response_data = response.json()
        repos.extend(response_data)
        url = response.links.get('next', {}).get('url')
    return repos

# å„ãƒªãƒã‚¸ãƒˆãƒªã®è¨€èªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
def fetch_languages(repo):
    url = repo['languages_url']
    headers = {
        'Authorization': f'token {os.getenv("GITHUB_TOKEN")}'
    }
    response = requests.get(url, headers=headers)
    return response.json()


# ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
def fetch_repository_files_recursive(contents_url, headers):
    """ æŒ‡å®šã•ã‚ŒãŸURLã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å†å¸°çš„ã«å–å¾— """
    files = []
    response = requests.get(contents_url, headers=headers)
    if response.status_code != 200:
        print(f"Failed to fetch contents: {response.status_code}")
        return files
    
    items = response.json()
    for item in items:
        if item["type"] == "file":
            files.append(item)
        elif item["type"] == "dir":
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆã€å†å¸°çš„ã«ãã®ä¸­èº«ã‚’å–å¾—
            files.extend(fetch_repository_files_recursive(item["url"], headers))
    return files

# å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
def analyze_repository_files(repositories):
    language_data = defaultdict(lambda: {"file_count": 0, "total_steps": 0, "import_counts": Counter(),"max_steps": 0})
    headers = {'Authorization': f'token {os.getenv("GITHUB_TOKEN")}'}
    
    for repo in repositories:
        repo_name = repo['name']
        contents_url = repo.get('contents_url', '').replace('{+path}', '')
        print(f"Fetching files for repository: {repo_name}")

        # å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—
        files = fetch_repository_files_recursive(contents_url, headers)
        
        for file in files:
            if isinstance(file, dict) and file.get("type") == "file":
                file_path = file["path"]
                file_download_url = file.get("download_url")
                print(f"Analyzing file: {file_path}")

                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—
                file_response = requests.get(file_download_url, headers=headers)
                if file_response.status_code != 200:
                    print(f"Failed to download file {file_path}: {file_response.status_code}")
                    continue

                file_content = file_response.text
                language = repo.get("language", "Unknown")
                lines = file_content.splitlines()
                step_count = len(lines)

                # æ›´æ–°: ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®åˆè¨ˆ
                language_data[language]["file_count"] += 1
                language_data[language]["total_steps"] += step_count  # ã“ã“ã§ total_steps ã‚’åŠ ç®—
                language_data[language]["max_steps"] = max(language_data[language]["max_steps"], step_count)  # æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ›´æ–°

                # importæ–‡ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                imports = re.findall(r'^\s*(import\s+\w+|from\s+\w+\s+import)', file_content, re.MULTILINE)
                language_data[language]["import_counts"].update(imports)
    
    return language_data
    
# è¨€èªä½¿ç”¨ç‡ã‚’ã€Œãƒ•ã‚¡ã‚¤ãƒ«æ•° * ã‚¹ãƒ†ãƒƒãƒ—æ•°ã€ã§è¨ˆç®—
def calculate_language_usage(language_data):
    # å„è¨€èªã® total_steps ã®åˆè¨ˆã‚’è¨ˆç®—ï¼ˆtotal_steps ãŒãªã„å ´åˆã¯ 0ï¼‰
    total_steps_all_languages = sum(data.get("total_steps", 0) for data in language_data.values())
    language_usage = {
        language: round((data.get("total_steps", 0) / total_steps_all_languages) * 100, 2)
        for language, data in language_data.items()
    }
    return language_usage
    
# è¨€èªä½¿ç”¨å††ç’°ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã¦ä¿å­˜
def save_language_pie_chart(language_usage, filename="language_usage.png"):
    labels = []
    sizes = []
    filtered_labels = []
    filtered_sizes = []
    threshold = 5  # %ãŒ5%ä»¥ä¸‹ã®ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤ºã«ã™ã‚‹

    # è¨€èªãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ©ãƒ™ãƒ«è¨­å®š
    for language, size in language_usage.items():
        labels.append(language)
        sizes.append(size)
        if size >= threshold:
            filtered_labels.append(f"{language} ({size}%)")
            filtered_sizes.append(size)
        else:
            filtered_labels.append("")
            filtered_sizes.append(size)

    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(aspect="equal"))

    # å††ç’°ã‚°ãƒ©ãƒ•ã®ä½œæˆï¼ˆæ“¬ä¼¼çš„ã«ç«‹ä½“æ„Ÿã‚’å‡ºã™ï¼‰
    wedges, texts = ax.pie(
        filtered_sizes,
        startangle=140,
        colors=monet_colors[:len(filtered_labels)],  # ãƒ¢ãƒé¢¨ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
        wedgeprops=dict(width=0.3, edgecolor='w')  # 3Dé¢¨ã®ç«‹ä½“æ„Ÿ
    )

    # ãƒ¬ã‚¸ã‚§ãƒ³ãƒ‰ã®è¨­å®š
    ax.legend(wedges, labels, title="Languages", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

    # ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦‹ãŸç›®ã®èª¿æ•´
    ax.set_title("Language Usage Chart", pad=20, fontsize=14, fontweight="bold", color="#3f5b85")
    fig.patch.set_facecolor("#333333")  # èƒŒæ™¯è‰²ã‚’ãƒ€ãƒ¼ã‚¯ã«ã—ã¦8ãƒ“ãƒƒãƒˆé¢¨ã«

    # ç”»åƒã®ä¿å­˜
    plt.savefig(filename, format="png", bbox_inches="tight", transparent=True)
    plt.close()

# READMEã‚’æ›´æ–°
def save_readme(language_usage, language_data):
    # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—
    update_time = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')

    with open("README.md", "w") as f:
        f.write("# Hi there ğŸ‘‹\n\n")
        f.write("## Language Usage\n\n")
        f.write(f">[!NOTE]\n> **Last updated: {update_time}**\n\n")
        
        f.write(f">![Python](https://img.shields.io/badge/Language-Python-blue) ![C](https://img.shields.io/badge/Language-C-lightgrey) ![JavaScript](https://img.shields.io/badge/Language-JavaScript-yellow)\n")
        f.write(f">![HTML](https://img.shields.io/badge/Language-HTML-orange) ![CSS](https://img.shields.io/badge/Language-CSS-blueviolet) ![Solidity](https://img.shields.io/badge/Language-Solidity-gray)\n")
        f.write(f">![R](https://img.shields.io/badge/Language-R-lightblue) ![Node.js](https://img.shields.io/badge/Language-Node.js-green) ![Scala](https://img.shields.io/badge/Language-Scala-red) \n\n")

        f.write(f">[!CAUTION]\n> **language_usage = total_steps_languages:** \n\n")
        # è¨€èªã¨ãã®å‰²åˆã‚’è¨˜è¼‰
        for language, percentage in language_usage.items():
            f.write(f"- {language}: {percentage}%\n")
        
        f.write("\n![Language Usage Chart](language_usage.png)\n")
                # ãƒˆãƒƒãƒ—3ã®è¨€èªã®è©³ç´°ã‚’è¿½åŠ 
        f.write("\n## Language Details (Top 3)\n")
        top_3_languages = sorted(language_usage.keys(), key=lambda x: language_usage[x], reverse=True)[:3]
        for language in top_3_languages:
            data = language_data.get(language, {"file_count": 0, "max_steps": 0, "import_counts": Counter()})
            f.write(f"\n### {language}\n")
            f.write(f"- File count: {data['file_count']}\n")
            f.write(f"- Max steps in a file: {data.get('max_steps', 'N/A')}\n")

# è¨€èªã”ã¨ã®è©³ç´°ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
def save_language_details(language_data, filename="language_details.json"):
    # Counterã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦JSONã«ä¿å­˜å¯èƒ½ãªå½¢å¼ã«
    formatted_data = {
        language: {
            "file_count": data["file_count"],
            "max_steps": data["max_steps"],
            "top_imports": data["import_counts"].most_common(5)
        }
        for language, data in language_data.items()
    }

    with open(filename, "w") as f:
        json.dump(formatted_data, f, indent=4)


def main():
    # ãƒªãƒã‚¸ãƒˆãƒªã®è¨€èªä½¿ç”¨ç‡ã‚’å–å¾—ãƒ»è¨ˆç®—
    repositories = fetch_repositories()
    language_data = analyze_repository_files(repositories)  # language_data ã‚’å–å¾—
    language_usage = calculate_language_usage(language_data)  
    
    
    # è¨€èªä½¿ç”¨ç‡ãƒ‡ãƒ¼ã‚¿ã‚’jsonã§ä¿å­˜
    with open("language_usage.json", "w") as f:
        json.dump(language_usage, f)
    
    # è¨€èªä½¿ç”¨ç‡ã®å††ç’°ã‚°ãƒ©ãƒ•ã¨READMEã®ä¿å­˜
    save_language_pie_chart(language_usage)
    save_readme(language_usage, language_data)
    
    # è¨€èªã”ã¨ã®è©³ç´°æƒ…å ±ã‚’ä¿å­˜
    save_language_details(language_data)

if __name__ == "__main__":
    main()
